### 2.2.5 基于图的向量索引方法

基于图的向量索引是目前向量数据库中使用最广泛，查询性能最高的索引类型之一。
然而，图索引的发展历史并不如其他经典向量索引类型那样长。
最早用于KNN查询的图索引是KNN图，它的一种高效近似构建算法NN-descent在2011年被提出。
后续研究者将KNN图与小世界网络模型（small-world network）相结合，逐步开发出NSW，HNSW，NSG等索引，在深度神经网络输出的嵌入向量上获得显著的查询性能提升。
本章节以经典的KNN图和HNSW为例，介绍图向量索引的概念、原理和算法。

#### 2.2.5.1 概述
基于图的向量索引将数据集中的每个向量表示为图中的一个点，同时根据向量间的距离（或称为相似性）为图赋边。不同图索引结构主要指不同的赋边策略。现代图索引多为有向图，也有部分为无向图。若图中存在一条边从节点a指向节点b，我们称节点b是节点a的邻居节点。



图索引的设计动机来自于小世界网络模型中的六度分隔理论。举一个通俗的例子，在人类社会的社交网络中（网络中的边为社交关系），从任何一个节点出发，在6步之内可以到达大部分网络中的节点。那么若以类似的方式将向量组织成网络（图），便可以从任意入口点出发，在较少步数内，到达查询点的最近邻。

![toy-example](../../images/chap2/toy_example.png)
<div align=center>
<p>图2.1 图索引的一个例子</p>
</div>

受小世界网络模型的启发，图索引也设计了贪婪的查询算法。如图2.1，给定一个查询点（query），图索引会选定一个入口点（entry point），然后从其邻居节点中选择最靠近查询点作为下一步。重复此过程，当前点会逐步靠近查询点，并最终收敛，即，当前点比所有的邻居点更靠近查询点。该算法通常也被称为“最佳优先搜索”（best-first-search）。注意，算法收敛后得到的节点向量并不总是精确的最近邻，即收敛到了局部最优（local optimum）而非全局最优（global optimum）。因此，图索引查询算法往往不能提供结果的精度保障。但是，在某些特殊的图结构中，可以证明算法找到的局部最优即为全局最优。



图索引的查询代价通常由距离计算次数度量。在贪婪查询算法中，查询代价由两部分构成：搜索路径长度，和平均邻居个数。在搜索的每一步上，需要计算邻居节点和查询节点之间的距离。这引出了图索引结构的一个重要设计权衡：稀疏性—导航性权衡。总的来说，图越稀疏，每一步的计算代价越低，算法效率越高；相反，图越稠密，从入口点到达最近邻点的期望路径长度越短，算法效率越高。因此，为实现最优的查询性能，图索引的设计需要在稀疏性和导航性之间寻取一个最优的平衡。



注意上述查询算法是在$k=1$时的简化版本，且无法通过参数控制精度和效率的权衡。我们将在下一节中介绍$k>1$的场景和集束搜索的扩展。尽管如此，上述分析同样适用于扩展搜索算法。



#### 2.2.5.2 KNN图

##### 2.2.5.2.1 索引结构

顾名思义，KNN图中，每个节点指向其K个最近邻。注意，最近邻关系不是对称关系。也就是说，若节点A是节点B的最近邻，节点B不一定是节点A的最近邻。因此，一般来说，KNN图是有向图。



KNN图通常认为是Delaunay图的一种近似，而Delaunay图可以保证使用贪婪搜索算法可以找到精确最近邻。如图2.2 (a)，Delaunay图（实线部分）和Voronoi图（虚线部分）在几何上是对称关系。



以二维平面为例，将数据集中的点（即图中灰色点）视为锚点，若其它某一未知的点距离锚点A比其它锚点都更近，那么这一位置视为归属于锚点A的Voronoi网格。图2.2 (a) 中各个虚线围成的多边形即为各个锚点的Voronoi网格。锚点必定会位于自己的Voronoi网格内。



若两个锚点的Voronoi网格是相连的，在Delaunay图上会为这个两个锚点之间连边。注意到，在几何上，若两个锚点之间直线相连，得到的边将“垂直平分”两个Voronoi网格的边界。直观上说，在Delaunay图上，节点会连接在各个方向上和自己最靠近的点作为邻居。因次，在KNN图中，节点通过连接和自己距离最近的固定K个邻居来模拟近似Delaunay图。

![delauney](../../images/chap2/delauney.png)

<div align=center>
<p>图2.2 Delaunay图与KNN图</p>
</div>

尽管Delaunay图有着精确的查询保障，但其在高维空间上趋近于完全图，不仅带来极高的构建代价，而且不具备稀疏性，导致较差的实际查询性能。因此，对Delaunay图做度数限制或其它近似手段（如KNN图）是更为常见的图索引设计方法。KNN图在公开数据集上表现出了优越的查询性能，但是，包括KNN图在内的现有大部分基于Delaunay图的图索引，通常是Delaunay图的子图，已经失去了精确查询保证。这意味着尽管它们获得了较好的实际性能，但仍然缺少理论基础。



##### 2.2.5.2.2 查询算法

本节介绍KNN图的近似$k$NN查询算法。此算法是2.2.5.1节的扩展版本，同时适用于目前大部分先进的图索引。



代码2.1展示了搜索的主要过程。贪婪查询算法的核心是通过维护一个定长为$L$（$L$≥$k$）的优先级队列$C$，来保存目前找到的最靠近查询点的数据点，并以此确定查询路径的下一步的节点。

具体来说，队列$C$中的项包含三个信息，数据点，数据点到查询点的距离，以及数据点是否已在队列中被访问过。队列$C$按照数据点到查询点的距离由近及远排序。$C$初始化时加入入口点$ep$。

另外，为避免搜索时冗余的距离计算，算法额外维护一个集合$V$，存储探测过的节点（计算过与查询点的距离）。同样，$V$初始时加入入口点$ep$。

算法的核心逻辑是7-15行的循环过程，循环每次访问队列$C$中一个未访问过的节点$vp$，探测$vp$的邻居节点并加入到队列中。探测结束后，若队列中超过$L$个点，则将当前队列中距离查询点最远的一些项丢弃，仅保留最靠近查询点的$L$个点。

当队列$C$中所有节点均已访问过时，算法收敛，循环结束。此时，意味着所有在查询路径上探测过的节点距离查询点的距离都比队列$C$中留存下来的点要更远。最后，算法将队列$C$中前$k$项中的节点返回给用户。

<div align=center>
<p>代码2.1：图的近似KNN搜索算法</p>
</div>

```pseudocode
approx_kNN_Graph_Search(图 G, 查询点 q, 入口点 ep, 参数k, L)

> 初始化一个空的优先级队列C，C中每一项的形式为(点, 点到查询点的距离, 是否已访问)。 C中的项按照距离从小到大排序。
> 将(ep, δ(ep, q), false)加入C。
> 初始化一个空的集合V，代表已探测过的节点。
> 将ep加入V。
> While 存在C中的项没有访问过：
>	令p=(vp, δp, ap)为C中第一个未访问的项（即ap = false）
>   ap = true
>   For n ∈ G[vp]：
>		if n not in V:
>			将(n, δ(n, q), false)加入C。
>			将n加入V。
>   if |C| > L:
>		截断队列C，仅保留前L项。
> 返回C中前k项中的点。
```



讨论：

1. 搜索路径：在$k$NN的搜索过程中，搜索路径并非如图2.1所示意的是一条单向路径。实际的搜索”路径“是一棵树，搜索算法可能沿着多个方向尝试寻找结果，最终返回的$k$个结果也可能由来自多个方向的数据点拼凑成。注意到贪婪搜索算法通常称为”最优优先搜索“（Best-First-Search），而非广度优先搜索（BFS, Breadth-First-Search）。
2. 局部最优：在KNN图上，贪婪算法不能确保找到的结果是全局最优的。算法可以保证访问过的点的一阶邻居到查询点的距离是更远的，但无法保证二阶邻居（即，邻居的邻居）和高阶邻居的情况。因此，贪婪算法可能陷入局部最优。
3. 精确性-效率权衡：在ANN索引算法中，通常可以通过参数来控制搜索力度。更大的搜索力度会延长查询时间，同时提高查询精确性。在贪婪搜索算法中，参数$L$，即优先级队列$C$的容量，代表搜索力度。更长的优先级队列可以允许访问更多点，也有更大的机会逃离局部最优，获得高质量的结果。但是，$L$和搜索力度（或查询时间）并不是线性关系。也就是说，增大1倍$L$可能导致查询时间延长2倍，需要根据实际情况确定。在工程实现中，通常将贪婪算法做变种，引入一个额外参数来限制查询的最多步数，以此来控制稳定的查询时间。





##### 2.2.5.2.3 近似构建算法

构建精确的KNN图需要精确寻找每个数据集中节点的K个最近邻，为了降低这个精确查询的代价，KNN图一般以近似的方式构建。本节以著名的NN-descent算法为例，介绍构建近似KNN图的基本原理。



NN-descent算法的核心思想可以由一句话概括：”我邻居的邻居也可能是我的邻居“。也就是说，假设已经存在一个近似KNN图，我们可以通过访问当前节点的邻居的邻居，来更新提升当前节点的邻居列表。因此，近似KNN图可以通过迭代-优化的方式逐步构建。具体来说，NN-descent算法包含以下几个步骤：

- 初始化：通过随机选点初始化一个KNN图。
- 迭代：
  - 对于数据集中每一个点v，从图中取得它的K个邻居，以及若干反向邻居（把v当做邻居的节点），合并为集合B；
  - 对于B中的每一个点u，在图中取得其K个邻居以及若干反向邻居，合并为集合B';
  - 计算v和B'中每一个点的距离，尝试更新v的邻居列表。
- 终止：若一轮迭代，没有产生任何一次更新，算法收敛终止。



对NN-descent算法有许多有效的优化算法：

- 局部连接：将探测二阶邻居转化为一阶邻居之间互相探测，即“我的邻居互相之间也可能是邻居”。这种方法没有改变比较次数，却降低了从图中寻找邻居的代价。
- 初始化：可以通过一个初步快速的，低精度的索引（比如kd树）来做KNN图的初始化，加快算法收敛。
- 冗余计算避免：随着迭代的进行，某些相邻点可能会多次计算距离导致冗余，可以通过加标记来减少冗余计算。



